{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacion del detector de fondo naive utilizando la mediana como estimador.\n",
    "\n",
    "Comienzo definiendo las funciones init_N_frames para seleccionar N frames aleatorios dentro del video para calcular la mediana. \n",
    "Luego la funcion calculate_median para calcular la mediana de los frames recibidos y asi obtener el estimador del fondo. Aplico desenfoque gaussiano para suavizar la imagen y trabajo en escala de grises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_N_frames(cap,N):\n",
    "    frames=[]\n",
    "    total_frames=cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frames_id=np.random.uniform(size=N)\n",
    "    for f in frames_id:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,f)\n",
    "        ret,frame=cap.read()\n",
    "        frames.append(frame)\n",
    "    return(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(frames,N): \n",
    "        mediana = np.median(np.array(random.choices(frames, k=N)), axis=0).astype(dtype=np.uint8)\n",
    "        mediana = cv2.normalize(mediana, mediana, 0, 255, cv2.NORM_MINMAX).astype('uint8') \n",
    "        mediana = cv2.GaussianBlur(mediana, (3, 3), 0)  \n",
    "        mediana_gray = cv2.cvtColor(mediana, cv2.COLOR_BGR2GRAY)\n",
    "        return mediana_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_back_detection(cap,N,t):#recibo video, Nro de frames para calcular la mediana, tiempo para recalcular el fondo\n",
    "    start_time = time.time()\n",
    "    ret,frame=cap.read()\n",
    "    fps = math.ceil(cap.get(cv2.CAP_PROP_FPS)) \n",
    "    w = int(cap.get(3)) \n",
    "    h= int(cap.get(4))\n",
    "    salida = cv2.VideoWriter('naive_back_det_resul_6.mp4', cv2.VideoWriter_fourcc(*'XVID'), fps, (w,h))\n",
    "    #inicializacion de variables \n",
    "    frames=[]\n",
    "    rec_frames=[]\n",
    "    cont_frames=0\n",
    "    actualizar_back=t*fps#calculo el nro de frames para actualizar el fondo\n",
    "    frames=init_N_frames(cap,N)#obtengo N frames aleatorios para calcular la mediana\n",
    "    mediana_gray=calculate_median(frames,N) #calculo la mediana   \n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        cont_frames+=1 \n",
    "        if not ret:\n",
    "            break\n",
    "        rec_frames.append(frame)#voy guardando los frames para recalcular luego el nuevo fondo\n",
    "        if cont_frames==actualizar_back:\n",
    "            cv2.putText(frame, \"Recalculando fondo\" , (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),2)\n",
    "            mediana_gray=calculate_median(rec_frames,N)#vuelvo a calcular la mediana \n",
    "            cont_frames=0\n",
    "        frame_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray= cv2.GaussianBlur(frame_gray, (3, 3), 0) \n",
    "        diff=cv2.absdiff(frame_gray,mediana_gray) #hago la resta para que solo queden los objetos \n",
    "        th,diff_th=cv2.threshold(diff,50,255,cv2.THRESH_BINARY)#binarizo para obtener mejores resultados \n",
    "        cnts = cv2.findContours(diff_th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]#busco los contornos en la imagen binarizada\n",
    "        for cnt in cnts:\n",
    "                if cv2.contourArea(cnt) > 500:#filtro para descartar algunos objetos que no sean los de interes\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    cv2.rectangle(frame, (x,y), (x+w, y+h),(0,255,0), 2)\n",
    "        salida.write(frame)\n",
    "    salida.release()\n",
    "    end_time=time.time()        \n",
    "    cap.release()\n",
    "    print(\"Tiempo de procesamiento:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion utilizo una funcion de openCV que aplica un metodo basado en mezcla de gaussianas para comparar los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOG2(cap):\n",
    "    start_time = time.time()\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    fps = math.ceil(cap.get(cv2.CAP_PROP_FPS)) \n",
    "    w = int(cap.get(3)) \n",
    "    h= int(cap.get(4))\n",
    "    salida = cv2.VideoWriter('MOG2.mp4', cv2.VideoWriter_fourcc(*'XVID'), fps, (w,h))\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break      \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray=cv2.GaussianBlur(gray, (3, 3), 0)       \n",
    "        fgmask = fgbg.apply(gray)\n",
    "        _,th=cv2.threshold(fgmask,150,255,cv2.THRESH_BINARY)\n",
    "        cnts = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        for cnt in cnts:\n",
    "            if cv2.contourArea(cnt) > 300:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(frame, (x,y), (x+w, y+h),(0,255,0), 2)\n",
    "        salida.write(frame)   \n",
    "    end_time=time.time()        \n",
    "    salida.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Tiempo de procesamiento:\",end_time-start_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo ambos metodos con distintos parametros y comparo resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 9.911282777786255\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "naive_back_detection(cap,25,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 14.6244957447052\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "naive_back_detection(cap,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de procesamiento: 7.9368321895599365\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "MOG2(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hice varias pruebas para ver la variacion en el tiempo del procesamiento y pude comprobar que menor es el tiempo que seteamos para recalcular el fondo, mas tarda ya que debe realizar las operaciones mayor cantidad de veces. Mas dilatamos este tiempo, mas velocidad obtenemos y mas parecido al resultado utilizando MOG2 de opencv. \n",
    "\n",
    "Hay algunos frames donde queda detectando cuadros que en frames anteriores hubo movimiento. Estos desaparecen en cuanto se recalcula el fondo, por lo cual es algo muy importante de tener en cuenta y lo mejor seria recalcular en cortos lapsos de tiempo, esto si sacrificando la velocidad del procesamiento como explicaba en el item anterior. \n",
    "\n",
    "Otro detalle que tiene este metodo es que cuando varias personas estan cruzandose, o estan cerca, las toma como un solo cuadro. Probe con distintas operaciones morfologicas para poder evitar esto pero no lograba buenos resultados, separaba quizas las personas pero tambien perdia partes del cuerpo. Por lo tanto decidi tomarlo como una sola figura. Esto se debe tener en cuenta dependiendo la aplicacion para la que necesitemos el algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac89dbf135de3ba50f0c4188f4f908fa9273f5adb06897823e082ae6e551143b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
